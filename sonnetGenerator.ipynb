{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From fairest creatures we desire increase,\n",
      "That thereby beauty’s rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou contracted to thine own bright eyes,\n",
      "Feed’st thy light’s flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thyself thy foe, to thy sweet self too cruel:\n",
      "Thou that art now the world’s fresh ornament,\n",
      "And only herald to the gaudy spring,\n",
      "Within thine own bud buriest thy content,\n",
      "And, tender churl, mak’st waste in niggarding:\n",
      "  Pity the world, or else this glutton be,\n",
      "  To eat the world’s due, by the grave and thee.\n",
      "\n",
      "from fairest creatures we desire increase that face should form another whose fresh ornament and thine this glutton be die but as the tillage of thine own deep sunken eyes were to eat the tillage of thy light s fresh repair if thou not to thy mother s glass and\n"
     ]
    }
   ],
   "source": [
    "import nltk, re, random\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, deque\n",
    "from document1 import training_doc1\n",
    "from document2 import training_doc2\n",
    "from document3 import training_doc3\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "\n",
    "class MarkovChain:\n",
    "  def __init__(self):\n",
    "    self.lookup_dict = defaultdict(list)\n",
    "    self._seeded = False\n",
    "    self.__seed_me()\n",
    "\n",
    "  def __seed_me(self, rand_seed=None):\n",
    "    if self._seeded is not True:\n",
    "      try:\n",
    "        if rand_seed is not None:\n",
    "          random.seed(rand_seed)\n",
    "        else:\n",
    "          random.seed()\n",
    "        self._seeded = True\n",
    "      except NotImplementedError:\n",
    "        self._seeded = False\n",
    "    \n",
    "  def add_document(self, str):\n",
    "    preprocessed_list = self._preprocess(str)\n",
    "    pairs = self.__generate_tuple_keys(preprocessed_list)\n",
    "    for pair in pairs:\n",
    "      self.lookup_dict[pair[0]].append(pair[1])\n",
    "  \n",
    "  def _preprocess(self, str):\n",
    "    cleaned = re.sub(r'\\W+', ' ', str).lower()\n",
    "    tokenized = word_tokenize(cleaned)\n",
    "    return tokenized\n",
    "\n",
    "  def __generate_tuple_keys(self, data):\n",
    "    if len(data) < 1:\n",
    "      return\n",
    "\n",
    "    for i in range(len(data) - 1):\n",
    "      yield [ data[i], data[i + 1] ]\n",
    "      \n",
    "  def generate_text(self, max_length=50):\n",
    "    context = deque()\n",
    "    output = []\n",
    "    if len(self.lookup_dict) > 0:\n",
    "      self.__seed_me(rand_seed=len(self.lookup_dict))\n",
    "      chain_head = [list(self.lookup_dict)[0]]\n",
    "      context.extend(chain_head)\n",
    "      \n",
    "      while len(output) < (max_length - 1):\n",
    "        next_choices = self.lookup_dict[context[-1]]\n",
    "        if len(next_choices) > 0:\n",
    "          next_word = random.choice(next_choices)\n",
    "          context.append(next_word)\n",
    "          output.append(context.popleft())\n",
    "        else:\n",
    "          break\n",
    "      output.extend(list(context))\n",
    "    return \" \".join(output)\n",
    "\n",
    "my_markov = MarkovChain()\n",
    "print(training_doc1)\n",
    "my_markov.add_document(training_doc1)\n",
    "my_markov.add_document(training_doc2)\n",
    "my_markov.add_document(training_doc3)\n",
    "generated_text = my_markov.generate_text()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sonnet formatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I consider how my light is spent, Ere half my\n",
      "days in this dark world be past, And that\n",
      "within a fading globe I waste\n",
      "Breathless hours of precious time, misspent.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_sonnet(text):\n",
    "  \"\"\"Formats a string into a sonnet structure without a rhyme scheme.\n",
    "\n",
    "  Args:\n",
    "      text: The string to format.\n",
    "\n",
    "  Returns:\n",
    "      A string formatted as a sonnet with 14 lines, \n",
    "      without any specific rhyme scheme.\n",
    "  \"\"\"\n",
    "  # Split the text into words\n",
    "  words = text.split()\n",
    "\n",
    "  # Define the sonnet line structure\n",
    "  line_length = 14\n",
    "  lines = []\n",
    "  current_line = []\n",
    "\n",
    "  # Loop through the words and add them to lines\n",
    "  for word in words:\n",
    "    if len(current_line) + len(word) <= line_length:\n",
    "      current_line.append(word)\n",
    "    else:  \n",
    "      lines.append(\" \".join(current_line))\n",
    "      current_line = [word]\n",
    "\n",
    "  # Add the last line (if necessary)\n",
    "  if current_line:\n",
    "    lines.append(\" \".join(current_line))\n",
    "\n",
    "  # Ensure we have 14 lines (pad with empty strings if needed)\n",
    "  lines += [\"\"] * (14 - len(lines))\n",
    "\n",
    "  return \"\\n\".join(lines)\n",
    "\n",
    "# Example usage\n",
    "text = \"When I consider how my light is spent, Ere half my days in this dark world be past, And that within a fading globe I waste Breathless hours of precious time, misspent.\"\n",
    "sonnet = format_sonnet(text)\n",
    "print(sonnet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate with the sonnet formatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fairest creatures we desire increase that face thou feel st thy\n",
      "glass and she so thou\n",
      "contracted to be die but if thou art old and see thy\n",
      "foe to be to be a tattered weed of mine\n",
      "shall besiege thy mother s field thy brow and\n",
      "thriftless praise\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_markov2 = MarkovChain()\n",
    "my_markov2.add_document(training_doc1)\n",
    "my_markov2.add_document(training_doc2)\n",
    "my_markov2.add_document(training_doc3)\n",
    "generated_text = my_markov2.generate_text()\n",
    "newSonnet = format_sonnet(generated_text)\n",
    "print(newSonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output: \n",
    "\n",
    "> from fairest creatures we desire increase that face thou feel st thy\n",
    "> glass and she so thou\n",
    "> contracted to be die but if thou art old and see thy\n",
    "> foe to be to be a tattered weed of mine\n",
    "> shall besiege thy mother s field thy brow and\n",
    "> thriftless praise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fairest creatures we desire increase that thereby beauty lies\n",
      "where abundance lies thyself thy blood warm when forty\n",
      "winters shall sum my count and tell the world s\n",
      "glass and only herald to eat the world s glass and she so\n",
      "gazed on now the riper should by time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sonnet.sonnets4_10 import *\n",
    "\n",
    "my_markov.add_document(sonnet4)\n",
    "my_markov.add_document(sonnet5)\n",
    "my_markov.add_document(sonnet6)\n",
    "my_markov.add_document(sonnet7)\n",
    "my_markov.add_document(sonnet8)\n",
    "my_markov.add_document(sonnet9)\n",
    "\n",
    "generated_text = my_markov2.generate_text()\n",
    "newSonnet = format_sonnet(generated_text)\n",
    "print(newSonnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
